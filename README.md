# Computer Vision RPS
This is an implementation of the Rock-Paper-Scissors game using the [Teachable-Machine](https://teachablemachine.withgoogle.com/) computer vision system to detect the option (Rock, paper or scissors) the user is showing to the computer. This model was created using sample images of myself showing each option to the camera to train the different classes. A class named "Nothing" was used to represent the lack of an option being shown to the camera. The accuracy of the model depended heavily on the amount of samples used to train each class, and for robustness, a minimum of 1,000 was used to train each category. 

The trained model files are saved in the repository as `keras_model.h5` and `labels.txt`, which contain the structure/parameters of the model and the labels of the classes respectively. 

## Milestone 1

- The development environment for the project was set up, along with Github integration for the project.
  
```python
"""Insert your code here"""
```

> Insert an image/screenshot of what you have built so far here.

## Milestone 2

- In this milestone, the model was created using sample images of myself showing each option to the camera to train the different classes. A class named "Nothing" was used to represent the lack of an option being shown to the camera. The accuracy of the model depended heavily on the amount of samples used to train each class, and for robustness, a minimum of 1,000 was used to train each category. 

The trained model files are saved in the repository as `keras_model.h5` and `labels.txt`, which contain the structure/parameters of the model and the labels of the classes respectively. 

## Milestone 3

- This milestone was soley for creating the virtual environment and installing required dependencies. Furthermore, the model was tested to verify functionality

## Milestone 4

